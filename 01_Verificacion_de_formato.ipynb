{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3ae2b7",
   "metadata": {},
   "source": [
    "# Verificacion de formato para cada .csv para que puedan ser transferibles a formato DarwinCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b964634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Los archivos csv se deben encontrar en la carpeta llamada 'Detecciones'\n",
    "ruta_carpeta = './Detecciones_crudas/'\n",
    "\n",
    "# Crear lista de archivos .csv en la carpeta\n",
    "csv_files = [os.path.join(ruta_carpeta, f) for f in os.listdir(ruta_carpeta) if f.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932aa3d",
   "metadata": {},
   "source": [
    "### Verificacion de columnas\n",
    "\n",
    "\n",
    "En la siguiente funcion se buscan organizar y estandarizar todas las bases de datos incluidas en el proyecto, para ello se:<br>\n",
    "<br>\n",
    "1. Cambia el nombre a las siguientes columnas, si esta no existe, se crea y se llena con \"NA\":<br>\n",
    "Start_time (s) a startTime<br>\n",
    "End_time (s) a endTime<br>\n",
    "Clements2024_Scientific_Name a speciesName<br>\n",
    "Confidence a confidence<br>\n",
    "original_file a filePath<br>\n",
    "punto a recorderID<br>\n",
    "project a projectName<br>\n",
    "aru_type a recorderModel<br>\n",
    "recorder a setupBy<br>\n",
    "segmentfile a segmentID<br>\n",
    "<br>\n",
    "2. Se hacen las siguientes transformaciones:<br>\n",
    "Se deja el nombre del archivo (sin la ruta completa) a mediaID<br>\n",
    "Si la columna deploymentGroups no existe, crea una nueva llamada deploymentGroups llenandola con \"NA\"<br>\n",
    "Verifica que latitud y longitus estan en formato de coordenadas geograficas<br>\n",
    "Verifica que los valores de confianza estan entre 0 y 1<br>\n",
    "Crea la timestamp y convierte en formato YYYY-MM-DD HH:MM:SS<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccf8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Standardizes a given detection DataFrame according to the specs provided.\n",
    "    Steps:\n",
    "        1. Rename columns, add missing if needed.\n",
    "        2. Apply required transformations.\n",
    "        3. Ensure and order required columns.\n",
    "        4. Rename segment_file as segmentID.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename \"original_file\" or \"file\" to \"filePath\" (do this before anything else)\n",
    "    if 'original_file' in df.columns:\n",
    "        df.rename(columns={'original_file': 'filePath'}, inplace=True)\n",
    "    elif 'File' in df.columns:\n",
    "        df.rename(columns={'File': 'filePath'}, inplace=True)\n",
    "    if 'filePath' not in df.columns:\n",
    "        df['filePath'] = \"NA\"\n",
    "\n",
    "    # Map of current to new column names, REMOVE 'original_file': 'mediaID' mapping.\n",
    "    rename_map = {\n",
    "        'Start_time (s)': 'startTime',\n",
    "        'End_time (s)': 'endTime',\n",
    "        'Clements2024_Scientific_Name': 'speciesName',\n",
    "        'Confidence': 'confidence',\n",
    "        'punto': 'recorderID',\n",
    "        'project': 'projectName',\n",
    "        'aru_type': 'recorderModel',\n",
    "        'recorder': 'setupBy'\n",
    "    }\n",
    "\n",
    "    # Apply renaming for the rest\n",
    "    for old, new in rename_map.items():\n",
    "        if old in df.columns:\n",
    "            df.rename(columns={old: new}, inplace=True)\n",
    "        if new not in df.columns:\n",
    "            df[new] = \"NA\"\n",
    "\n",
    "    # Now, create mediaID as the basename of filePath, place as second column\n",
    "    df['mediaID'] = df['filePath'].astype(str).apply(lambda x: os.path.basename(x) if x != \"NA\" else \"NA\")\n",
    "\n",
    "    # Add classifiedBy, deploymentStart, deploymentEnd, deploymentGroups, locality, municipality if not present\n",
    "    for col in ['classifiedBy', 'deploymentStart', 'deploymentEnd', 'deploymentGroups', 'locality', 'municipality']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"NA\"\n",
    "                \n",
    "    # --- Step 2: Transformations ---\n",
    "    # deploymentGroups: If not existing, already set to 'NA' above\n",
    "\n",
    "    # latitude & longitude should be float and valid\n",
    "    for lat_long_col in ['latitude', 'longitude']:\n",
    "        if lat_long_col in df.columns:\n",
    "            df[lat_long_col] = pd.to_numeric(df[lat_long_col], errors='coerce')\n",
    "            # Optionally: Check/clip to valid ranges\n",
    "            if lat_long_col == 'latitude':\n",
    "                df.loc[(df[lat_long_col] < -90) | (df[lat_long_col] > 90), lat_long_col] = pd.NA\n",
    "            else:\n",
    "                df.loc[(df[lat_long_col] < -180) | (df[lat_long_col] > 180), lat_long_col] = pd.NA\n",
    "\n",
    "    # Make sure confidence is a number between 0 and 1\n",
    "    if 'confidence' in df.columns:\n",
    "        df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "        # If it's, e.g., percentage, convert\n",
    "        if df['confidence'].max() > 1:\n",
    "            # Assume it's 0-100, convert\n",
    "            df['confidence'] = df['confidence'] / 100.0\n",
    "        # Force in range\n",
    "        df.loc[df['confidence'] < 0, 'confidence'] = 0\n",
    "        df.loc[df['confidence'] > 1, 'confidence'] = 1\n",
    "\n",
    "    # --- timestamp: from mediaID ---\n",
    "    def extract_timestamp(media_id):\n",
    "        # Expects format like G6370_20240212_103000.WAV or similar\n",
    "        if not isinstance(media_id, str):\n",
    "            return \"NA\"\n",
    "        # Remove extension\n",
    "        fname = os.path.splitext(media_id)[0]\n",
    "        # Split by \"_\"\n",
    "        parts = fname.split(\"_\")\n",
    "        if len(parts) < 2:\n",
    "            return \"NA\"\n",
    "        # Last two parts supposed to be e.g. 20240212, 103000\n",
    "        date_str = parts[-2]\n",
    "        time_str = parts[-1]\n",
    "        date_str = re.sub(r'[^\\d]', '', date_str)   # clean non-digit\n",
    "        time_str = re.sub(r'[^\\d]', '', time_str)\n",
    "        timestamp = f\"{date_str}_{time_str}\"\n",
    "        return timestamp\n",
    "\n",
    "    df['timestamp'] = df['mediaID'].apply(extract_timestamp)\n",
    "\n",
    "    # Convert timestamp to 'YYYY-MM-DD HH:MM:SS'\n",
    "    def reformat_timestamp(ts):\n",
    "        # Expects 'YYYYMMDD_HHMMSS' e.g. 20240212_103000\n",
    "        if isinstance(ts, str) and len(ts) >= 15 and \"_\" in ts:\n",
    "            date_part, time_part = ts.split(\"_\")\n",
    "            if len(date_part) == 8 and len(time_part) == 6:\n",
    "                return f\"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]} {time_part[:2]}:{time_part[2:4]}:{time_part[4:6]}\"\n",
    "        return pd.NA\n",
    "\n",
    "    df['timestamp'] = df['timestamp'].apply(reformat_timestamp)\n",
    "\n",
    "    # --- Step 3: Ensure columns exist and sort ---\n",
    "\n",
    "    # Update required_columns: add \"filePath\" as FIRST, \"mediaID\" as SECOND\n",
    "    required_columns = [\n",
    "        'filePath', 'mediaID','startTime', 'endTime', 'speciesName', 'confidence',\n",
    "        'classifiedBy', 'recorderID', 'recorderModel', 'locality',\n",
    "        'projectName', 'municipality','latitude', 'longitude', 'setupBy', 'deploymentStart',\n",
    "        'deploymentEnd', 'deploymentGroups','timestamp'\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"NA\"\n",
    "\n",
    "    # Handle 'segment_file' as 'segmentID', drop habitat if it exists\n",
    "    # If 'segmentID' already exists, do nothing.\n",
    "    if 'segmentID' not in df.columns:\n",
    "        if 'segment_file' in df.columns:\n",
    "            df.rename(columns={'segment_file': 'segmentID'}, inplace=True)\n",
    "        else:\n",
    "            df['segmentID'] = \"NA\"\n",
    "    if 'habitat' in df.columns:\n",
    "        df = df.drop(columns=['habitat'])\n",
    "\n",
    "    # Ensure all required columns in given order, fill missing (already done above)\n",
    "    # Now append 'segmentID' at the end\n",
    "    output_columns = required_columns + ['segmentID']\n",
    "    for col in output_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"NA\"\n",
    "    df = df[output_columns]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f527c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = standardize_dataframe(df)\n",
    "    output_folder = \"./Detecciones_estandarizadas\"\n",
    "    output_path = os.path.join(output_folder, os.path.basename(file))\n",
    "    df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
