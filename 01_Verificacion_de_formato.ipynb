{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3ae2b7",
   "metadata": {},
   "source": [
    "# Verificacion de formato para cada .csv para que puedan ser transferibles a formato DarwinCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b964634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Los archivos csv se deben encontrar en la carpeta llamada 'Detecciones'\n",
    "ruta_carpeta = './Detecciones_crudas/'\n",
    "\n",
    "# Crear lista de archivos .csv en la carpeta\n",
    "csv_files = [os.path.join(ruta_carpeta, f) for f in os.listdir(ruta_carpeta) if f.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932aa3d",
   "metadata": {},
   "source": [
    "### Verificacion de columnas\n",
    "\n",
    "\n",
    "En la siguiente funcion se buscan organizar y estandarizar todas las bases de datos incluidas en el proyecto, para ello se:<br>\n",
    "<br>\n",
    "1. Cambia el nombre a las siguientes columnas, si esta no existe, se crea y se llena con \"NA\":<br>\n",
    "Start_time (s) a startTime<br>\n",
    "End_time (s) a endTime<br>\n",
    "Clements2024_Scientific_Name a speciesName<br>\n",
    "Confidence a confidence<br>\n",
    "original_file a mediaID<br>\n",
    "punto a recorderID<br>\n",
    "project a projectName<br>\n",
    "aru_type a recorderModel<br>\n",
    "recorder a setupBy<br>\n",
    "<br>\n",
    "2. Se hacen las siguientes transformaciones:<br>\n",
    "Se deja el nombre del archivo (sin la ruta completa) a mediaID<br>\n",
    "Si la columna deploymentGroups no existe, crea una nueva llamada deploymentGroups llenandola con \"NA\"<br>\n",
    "Verifica que latitud y longitus estan en formato de coordenadas geograficas<br>\n",
    "Verifica que los valores de confianza estan entre 0 y 1<br>\n",
    "Crea la timestamp y convierte en formato YYYY-MM-DD HH:MM:SS<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ccf8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Standardizes a given detection DataFrame according to the specs provided.\n",
    "    Steps:\n",
    "        1. Rename columns, add missing if needed.\n",
    "        2. Apply required transformations.\n",
    "        3. Ensure and order required columns.\n",
    "        4. Add segmentID at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map of current to new column names\n",
    "    rename_map = {\n",
    "        'Start_time (s)': 'startTime',\n",
    "        'End_time (s)': 'endTime',\n",
    "        'Clements2024_Scientific_Name': 'speciesName',\n",
    "        'Confidence': 'confidence',\n",
    "        'original_file': 'mediaID',\n",
    "        'punto': 'recorderID',\n",
    "        'project': 'projectName',\n",
    "        'aru_type': 'recorderModel',\n",
    "        'recorder': 'setupBy'\n",
    "    }\n",
    "\n",
    "    # Columns we expect after renaming/creating\n",
    "    required_columns = [\n",
    "        'mediaID', 'startTime', 'endTime', 'speciesName', 'confidence',\n",
    "        'classifiedBy', 'recorderID', 'recorderModel', 'locality',\n",
    "        'projectName', 'municipality','latitude', 'longitude', 'setupBy', 'deploymentStart',\n",
    "        'deploymentEnd', 'deploymentGroups','timestamp'\n",
    "    ]\n",
    "\n",
    "    # --- Step 1: Rename columns and create missing ones as NA ---\n",
    "    for old, new in rename_map.items():\n",
    "        if old in df.columns:\n",
    "            df.rename(columns={old: new}, inplace=True)\n",
    "        if new not in df.columns:\n",
    "            df[new] = \"NA\"\n",
    "\n",
    "    # Add classifiedBy, deploymentStart, deploymentEnd, deploymentGroups, locality, municipality if not present\n",
    "    for col in ['classifiedBy', 'deploymentStart', 'deploymentEnd', 'deploymentGroups', 'locality', 'municipality']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"NA\"\n",
    "                \n",
    "    # --- Step 2: Transformations ---\n",
    "    # mediaID: basename (strip folders from filename)\n",
    "    if 'mediaID' in df.columns:\n",
    "        df['mediaID'] = df['mediaID'].astype(str).apply(lambda x: os.path.basename(x))\n",
    "\n",
    "    # deploymentGroups: If not existing, already set to 'NA' above\n",
    "\n",
    "    # latitude & longitude should be float and valid\n",
    "    for lat_long_col in ['latitude', 'longitude']:\n",
    "        if lat_long_col in df.columns:\n",
    "            df[lat_long_col] = pd.to_numeric(df[lat_long_col], errors='coerce')\n",
    "            # Optionally: Check/clip to valid ranges\n",
    "            if lat_long_col == 'latitude':\n",
    "                df.loc[(df[lat_long_col] < -90) | (df[lat_long_col] > 90), lat_long_col] = pd.NA\n",
    "            else:\n",
    "                df.loc[(df[lat_long_col] < -180) | (df[lat_long_col] > 180), lat_long_col] = pd.NA\n",
    "\n",
    "    # Make sure confidence is a number between 0 and 1\n",
    "    if 'confidence' in df.columns:\n",
    "        df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "        # If it's, e.g., percentage, convert\n",
    "        if df['confidence'].max() > 1:\n",
    "            # Assume it's 0-100, convert\n",
    "            df['confidence'] = df['confidence'] / 100.0\n",
    "        # Force in range\n",
    "        df.loc[df['confidence'] < 0, 'confidence'] = 0\n",
    "        df.loc[df['confidence'] > 1, 'confidence'] = 1\n",
    "\n",
    "    # --- timestamp: from mediaID ---\n",
    "    \n",
    "    def extract_timestamp(media_id):\n",
    "        # Expects format like G6370_20240212_103000.WAV or similar\n",
    "        if not isinstance(media_id, str):\n",
    "            return \"NA\"\n",
    "        # Remove extension\n",
    "        fname = os.path.splitext(media_id)[0]\n",
    "        # Split by \"_\"\n",
    "        parts = fname.split(\"_\")\n",
    "        if len(parts) < 2:\n",
    "            return \"NA\"\n",
    "        # Last two parts supposed to be e.g. 20240212, 103000\n",
    "        date_str = parts[-2]\n",
    "        time_str = parts[-1]\n",
    "        date_str = re.sub(r'[^\\d]', '', date_str)   # clean non-digit\n",
    "        time_str = re.sub(r'[^\\d]', '', time_str)\n",
    "        timestamp = f\"{date_str}_{time_str}\"\n",
    "        return timestamp\n",
    "\n",
    "    df['timestamp'] = df['mediaID'].apply(extract_timestamp)\n",
    "\n",
    "    # Convert timestamp to 'YYYY-MM-DD HH:MM:SS'\n",
    "    def reformat_timestamp(ts):\n",
    "        # Expects 'YYYYMMDD_HHMMSS' e.g. 20240212_103000\n",
    "        if isinstance(ts, str) and len(ts) >= 15 and \"_\" in ts:\n",
    "            date_part, time_part = ts.split(\"_\")\n",
    "            if len(date_part) == 8 and len(time_part) == 6:\n",
    "                return f\"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]} {time_part[:2]}:{time_part[2:4]}:{time_part[4:6]}\"\n",
    "        return pd.NA\n",
    "\n",
    "    df['timestamp'] = df['timestamp'].apply(reformat_timestamp)\n",
    "\n",
    "    # --- Step 3: Ensure columns exist and sort ---\n",
    "    # Ensure all required columns exist\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"NA\"\n",
    "\n",
    "    # Remove 'segment_file' and 'habitat' columns if they exist before sorting\n",
    "    for col_to_drop in ['segment_file', 'habitat']:\n",
    "        if col_to_drop in df.columns:\n",
    "            df = df.drop(columns=[col_to_drop])\n",
    "\n",
    "    # Sort all columns in the exact order of required_columns --\n",
    "    # fill in any missing columns (if any) with NA for shape compliance\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    for col in missing_cols:\n",
    "        df[col] = \"NA\"\n",
    "    df = df[required_columns]\n",
    "\n",
    "    # --- Step 4: Create segmentID column and place at the end ---\n",
    "    def create_segment_id(row):\n",
    "        media_id = row['mediaID']\n",
    "        start = row['startTime']\n",
    "        end = row['endTime']\n",
    "        # Remove extension from mediaID if present before adding start/end\n",
    "        media_base = os.path.splitext(str(media_id))[0]\n",
    "        segid = f\"{media_base}_{start}_{end}.wav\"\n",
    "        return segid\n",
    "\n",
    "    df['segmentID'] = df.apply(create_segment_id, axis=1)\n",
    "    # Move 'segmentID' to the end if not already at the end\n",
    "    col_list = list(df.columns)\n",
    "    if col_list[-1] != 'segmentID':\n",
    "        col_list = [c for c in col_list if c != 'segmentID'] + ['segmentID']\n",
    "        df = df[col_list]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84f527c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/xzrhlh5s5yd6q142xlf57x4h0000gn/T/ipykernel_73444/3483647549.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['segmentID'] = df.apply(create_segment_id, axis=1)\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = standardize_dataframe(df)\n",
    "    output_folder = \"./Detecciones_estandarizadas\"\n",
    "    output_path = os.path.join(output_folder, os.path.basename(file))\n",
    "    df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
